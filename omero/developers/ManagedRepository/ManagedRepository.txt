FS Managed Repository
=====================

Import overview
---------------

Insert diagram

Configuration properties
------------------------

- ``omero.data.dir`` - singleton property (i.e. once globally) which points 
  to the legacy repository location for OMERO. For OMERO to run on multiple 
  systems, the contents of this directory must be on a shared volume.

- ``omero.managed.dir`` - singleton property point to the default 
  ``ManagedRepository``. In an OMERO install in which there is only one Blitz 
  server, this will be the only repository. Need not be located under 
  ``omero.data.dir`` but is by default.

- ``omero.fs.repo.path`` - the template which determines the path that will be 
  created inside of a managed repository. It is this value which makes the 
  ``ManagedRepository`` “managed”.

- ``omero.repo.dir`` - value passed to all non-legacy, standalone 
  repositories. This is not actively used, but would allow hosting 
  repositories on multiple physical systems without the need for a shared 
  volume. For example, after running ``bin/omero admin start`` on the main 
  machine, it would be possible to launch nodes on various machines via 
  ``bin/omero node start fs-B``, ``bin/omero node start fs-C``, etc. Each of 
  these would pass a different ``omero.repo.dir`` value to its process.

Import workflow
---------------

Still be added

API sequence
------------

- Choose which files to import by either:
   - ``ImportLibrary`` and friends (Java only)
   - listing all files (not directories) manually.

- Choose a ``ManagedRepositoryPrx`` from 
  ``SharedResourcesPrx().repositories()``.

- Call either:
   - ``ImportLibrary.importImage()`` which calls 
     ``ManagedRepositoryPrx.importFilesets(Fileset, ImportSettings)``, or
   - directly use ``ManagedRepositoryPrx.importPaths(StringSet)``.

- Receive an ``ImportProcessPrx``.

- For each ``FileEntry`` in the ``FileSet`` or each path in the ``StringSet`` 
  (in order), call ``ImportProcessPrx.getUploader()`` and receive a 
  ``RawFileStorePrx``.

- Upload the file via ``RawFileStorePrx.write()`` while reading the files 
  locally to write, be sure to calculate the checksum.

- Pass a list of checksums (in order) to 
  ``ImportProcessPrx.verifyUpload(StringSet)``. If the hashes match, receive a 
  ``HandlePrx``. Otherwise an exception is thrown.

At this point, the client should be able to disconnect and the rest of the 
import should happen independently.

- Create an ``CmdCallbackI`` that wraps the ``HandlePrx`` and wait for 
  successful completion.

At this point, the main metadata import is finished, but background processing 
may still be occurring. Handles for the background processing will 
also be returned.

Model description
-----------------

.. note:: This section is still under development

See :file:`acquisition.ome.xml`

- ``ome.model.fs.Fileset``
   - Represents a group of files which are considered to belong together.
   - There is the possibility that a single client fileset will be one or more 
     datasets in Bio-Formats. We need to decide to either model this or to use 
     a special reader (DirectoryReader ?) on the server.
   - Also links to multiple ome.model.jobs.Job instances.
   - *In development*: links to the plate and image objects which are created 
     during import.

- ``ome.model.jobs.Job`` subclasses
   - Each one represents some action which takes place server-side on the 
     Fileset.
   - For the standard sequence described above, the first will always be an 
     ``UploadJob`` which contains version info from the client. If the 
     files were not uploaded however, this may not be the case. Then a 
     ``MetadataImportJob`` follows, which is the basic import.
   - Other jobs may be necessary for regular usage (``PixelDataJob``, 
     ``IndexingJob``, etc.). *Later jobs may also be added like a re-parse job 
     with another FilesetVersionInfo instance, a re-check of the sha1s to look 
     for corruption, or an archive job*.
   - For job definitions, see :file:`jobs.ome.xml`

- ``ome.model.fs.FilesetEntry``
   - Link from a ``Fileset`` to exactly one ``ome.model.core.OriginalFile``
   - Critically, it also contains the original absolute client path of that 
     file.

- ``ome.model.fs.FilesetVersionInfo``
   - *In development*: A snapshot of process information along with software 
     versions. Most important for knowing how files were parsed, therefore 
     when using ``importPaths``, a “synthetic” version info might be created 
     to say that these were just uploaded blindly.

Server-side classes/concepts
----------------------------

``AbstractRepositoryI`` and all of its subclasses are implementations of the 
InternalRepository API. These objects are for internal use only and should 
never be accessible by the clients. Each instance is initialized with a 
directory which the servant attempts to “acquire” (i.e. grab a lock file). 
Once it does so, it is the serving repository.

Each internal repository provides a public view which in turn provides the 
``Repository`` API. All method calls assume Unix-style strings, which are 
guaranteed by ``CheckedPath``, a loose wrapper around ``java.io.File``. 
CheckedPath objects along with the active ``Ice.Current`` instance are passed 
to the ``RepositoryDao`` interface, which provides database access for all 
repositories. Access to raw IO is provided by the ``RepoRawFileStoreI`` 
servant, which wraps a ``RawFileBean``. 

The ``ManagedRepository`` implementation is responsible for import and 
enforces further constraints (beyond those of CheckedPath) on where and what 
files are created. Most importantly, the ``omero.fs.repo.path`` template value 
is expanded and pre-pended to all uploads. A further responsibility of the 
``ManagedRepository`` is to maintain a list of all currently running 
``ManagedImportProcessI``, each of which is held in the ``ProcessContainer``. 
These ``ManagedImportProcessI`` instances further wrap ``RepoRawFileStoreI`` 
instances with a subclass, ``ManagedRawFileStoreI``. 


Server-side sequence
--------------------

Still be added


.. seealso:: :doc:`/sysadmins/fs-upload-configuration`



